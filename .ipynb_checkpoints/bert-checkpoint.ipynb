{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import pandas as pd \n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import keras\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['euTextClassifier_CM.ipynb', 'bert.ipynb', 'merged_scores.csv']\n"
     ]
    }
   ],
   "source": [
    "L = []\n",
    "csv_num = 0\n",
    "print(glob.glob('*'))\n",
    "for csv in glob.glob('*.csv'):\n",
    "#     if (csv != \"coder_1.csv\"):\n",
    "    df1 = pd.read_csv(csv, encoding='latin-1')\n",
    "    df1['File Number'] = csv\n",
    "    L.append(df1)\n",
    "    csv_num += 1\n",
    "    \n",
    "df = pd.concat(L, axis = 0, sort=False)\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "df.columns.str.rstrip()\n",
    "df.columns = df.columns.str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Question_Text           2852\n",
       "Question_ID             2861\n",
       "Euroskepticism_Score       2\n",
       "Nationalism_Score          2\n",
       "Populism_Score             2\n",
       "File_Number                1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Euroskepticism_Score'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Nationalism_Score'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Populism_Score'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[~df['Nationalism_Score'].isin([0. , 0.5, 1. ])]['File_Number'].unique()\n",
    "df.loc[df['Euroskepticism_Score'].isnull()]['File_Number'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Euroskepticism_Score', 'Populism_Score', 'Nationalism_Score'])\n",
    "df['Euroskepticism_Score'] = df['Euroskepticism_Score'].astype('float')\n",
    "df['Nationalism_Score'] = df['Nationalism_Score'].astype('float')\n",
    "df['Populism_Score'] = df['Populism_Score'].astype('float')\n",
    "df['Question_Text'] = df['Question_Text'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Question_Text           2853\n",
       "Question_ID             2861\n",
       "Euroskepticism_Score       2\n",
       "Nationalism_Score          2\n",
       "Populism_Score             2\n",
       "File_Number                1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_of_scores = dict()\n",
    "\n",
    "for question_id in df['Question_ID'].unique():\n",
    "    a = np.max(df[(df['Question_ID'] == question_id)]['Euroskepticism_Score'].fillna(0))\n",
    "    b = np.max(df[(df['Question_ID'] == question_id)]['Nationalism_Score'].fillna(0))\n",
    "    c = np.max(df[(df['Question_ID'] == question_id)]['Populism_Score'].fillna(0))\n",
    "    T = df[(df['Question_ID'] == question_id)]['Question_Text']\n",
    "#     file_num = df[(df['Question_ID'] == question_id)]['File Number']\n",
    "    max_of_scores[question_id] = [T[T.index[0]], question_id, a, b, c]\n",
    "\n",
    "scores = pd.DataFrame.from_dict(max_of_scores, orient = 'index')\n",
    "scores = scores.rename(columns = {0: 'Question_Text', 1: 'Question_ID', 2: 'Euroskepticism_Score', \n",
    "                                        3: 'Nationalism_Score', 4: 'Populism_Score'})\n",
    "scores.index = range(len(scores))\n",
    "\n",
    "scores['Question_Text'] = scores['Question_Text'].apply(lambda x: str(x))\n",
    "scores['Question_ID'] = scores['Question_ID'].apply(lambda x: str(x))\n",
    "# scores['Question_ID'] = scores['File Number'].apply(lambda x: str(x))\n",
    "for score_type in ['Euroskepticism_Score','Nationalism_Score', 'Populism_Score']:\n",
    "    scores[score_type] = scores[score_type].astype('float')\n",
    "    scores[score_type] = scores[score_type].apply(np.ceil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question_Text</th>\n",
       "      <th>Question_ID</th>\n",
       "      <th>Euroskepticism_Score</th>\n",
       "      <th>Nationalism_Score</th>\n",
       "      <th>Populism_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Further to the answer it gave to my Question E...</td>\n",
       "      <td>E-013527-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In Italy as in many other Member States legal ...</td>\n",
       "      <td>E-001570-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On 1 September 2013 Iraqi forces carried out a...</td>\n",
       "      <td>P-010965-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the Work Programme of the Agency for the Co...</td>\n",
       "      <td>E-011939-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Identification marking on foods which are avai...</td>\n",
       "      <td>E-003034-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>According to estimates in Germany alone every ...</td>\n",
       "      <td>E-002177-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>In the context of the review of the EU policy ...</td>\n",
       "      <td>E-003105-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Directive 2004/82/EC is intended to improve bo...</td>\n",
       "      <td>E-001109-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Directive 2004/82/EC is intended to improve bo...</td>\n",
       "      <td>E-001108-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>On 27 February 2013 Mr Kallas on behalf of the...</td>\n",
       "      <td>E-005785-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Commissioner for Home Affairs has apparent...</td>\n",
       "      <td>P-009654-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>On 1 January 2014 Commission Regulation EC No ...</td>\n",
       "      <td>P-007405-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The rights of every EU citizen include the fre...</td>\n",
       "      <td>E-001080-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>In divorce cases in Germany maintenance is dec...</td>\n",
       "      <td>E-003342-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The directive on the application of patients r...</td>\n",
       "      <td>E-009518-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>It has emerged that the negotiations held betw...</td>\n",
       "      <td>E-003113-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>By virtue of circular 2013/151663 concerning i...</td>\n",
       "      <td>E-001705-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The Transatlantic Trade and Investment Partner...</td>\n",
       "      <td>E-004788-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The Pescara Marina one of the largest of its k...</td>\n",
       "      <td>E-008226-14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Since 1 January 2014 the citizens of Bulgaria ...</td>\n",
       "      <td>E-000247-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0    The number of social networks on the Inte...</td>\n",
       "      <td>E-005382-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2    How would the High Representative charact...</td>\n",
       "      <td>E-009417-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>On 19 December 2011 a Congolese citizen Samba ...</td>\n",
       "      <td>E-004349-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Since the 2009 coup dÃÂÃÂÃÂÃÂ©tat which...</td>\n",
       "      <td>E-010806-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>I understand that correspondence has been exch...</td>\n",
       "      <td>E-010948-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>On 6 June 2013 a whistleblower exposed an exte...</td>\n",
       "      <td>E-006782-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>According to the Amended Work Programme 2013 o...</td>\n",
       "      <td>E-012119-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Recent media reports have clearly exposed the ...</td>\n",
       "      <td>E-005640-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>At the beginning of 2012 the operators of the ...</td>\n",
       "      <td>E-004662-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>When asked about the possibility that oil pric...</td>\n",
       "      <td>E-005857-13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2831</th>\n",
       "      <td>The Ebro Delta with its 22 000 hectares of ric...</td>\n",
       "      <td>E-002675-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2832</th>\n",
       "      <td>Hungary has decided to deploy armed forces up ...</td>\n",
       "      <td>E-013058-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>Due account must be taken in the following que...</td>\n",
       "      <td>E-008068-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2834</th>\n",
       "      <td>While larger conflicts including the continuin...</td>\n",
       "      <td>E-003054-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>The Pero Spaccone district on the Formicoso pl...</td>\n",
       "      <td>P-5647/08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>A few days ago the Italian press reported an a...</td>\n",
       "      <td>E-3260/07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>Maintenance technicians working for Aircraft I...</td>\n",
       "      <td>E-4798/07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2838</th>\n",
       "      <td>The Social Platform has informed me that the L...</td>\n",
       "      <td>E-0252/05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2839</th>\n",
       "      <td>In view of the fact that the Turkish Prime Min...</td>\n",
       "      <td>E-2443/05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2840</th>\n",
       "      <td>The Nitrates Directive 91/676/EEC1 requires Me...</td>\n",
       "      <td>P-4457/08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2841</th>\n",
       "      <td>According to various Arab diplomats the Tunisi...</td>\n",
       "      <td>E-4657/05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2842</th>\n",
       "      <td>1. Does the Commission remember that in March ...</td>\n",
       "      <td>E-1714/01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2843</th>\n",
       "      <td>Economic and social policy-makers in the Europ...</td>\n",
       "      <td>E-2418/01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2844</th>\n",
       "      <td>The Romanian Government has suspended internat...</td>\n",
       "      <td>P-2485/01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2845</th>\n",
       "      <td>Developing countries are in great need of a ma...</td>\n",
       "      <td>E-1790/99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2846</th>\n",
       "      <td>On 22 September 2004 Heineken stated that it w...</td>\n",
       "      <td>P-3527/04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2847</th>\n",
       "      <td>The Italian  ENI through its subsidiary Agip O...</td>\n",
       "      <td>P-1182/05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2848</th>\n",
       "      <td>The Directive of the European Parliament and o...</td>\n",
       "      <td>H-0532/05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2849</th>\n",
       "      <td>How many Erasmus and Erasmus Mundus students s...</td>\n",
       "      <td>E-006550-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2850</th>\n",
       "      <td>I have noticed that in some EU Member States i...</td>\n",
       "      <td>E-3399/00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2851</th>\n",
       "      <td>Will the Commission state whether there is a E...</td>\n",
       "      <td>E-1818/03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2852</th>\n",
       "      <td>With regard to my question H-0459/02 tabled on...</td>\n",
       "      <td>H-0601/02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2853</th>\n",
       "      <td>In the MÃÂÃÂÃÂÃÂ¼ller-FaurÃÂÃÂÃÂÃ...</td>\n",
       "      <td>P-3666/03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2854</th>\n",
       "      <td>The French authorities are reported to have su...</td>\n",
       "      <td>E-2057/97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2855</th>\n",
       "      <td>Will the Commission state how much of the appr...</td>\n",
       "      <td>E-3404/95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2856</th>\n",
       "      <td>Written Question P-3862/981 criticised the fai...</td>\n",
       "      <td>P-0201/00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2857</th>\n",
       "      <td>The international steel trade faces new challe...</td>\n",
       "      <td>E-3830/98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2858</th>\n",
       "      <td>Shortly after Serbia was granted candidate sta...</td>\n",
       "      <td>E-006504/2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2859</th>\n",
       "      <td>The increasing shortfall in the numbers of lic...</td>\n",
       "      <td>E-3161/06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2860</th>\n",
       "      <td>Given the move towards a more market-led Europ...</td>\n",
       "      <td>E-5091/07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2861 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Question_Text    Question_ID  \\\n",
       "0     Further to the answer it gave to my Question E...    E-013527-13   \n",
       "1     In Italy as in many other Member States legal ...    E-001570-13   \n",
       "2     On 1 September 2013 Iraqi forces carried out a...    P-010965-13   \n",
       "3     In the Work Programme of the Agency for the Co...    E-011939-13   \n",
       "4     Identification marking on foods which are avai...    E-003034-13   \n",
       "5     According to estimates in Germany alone every ...    E-002177-13   \n",
       "6     In the context of the review of the EU policy ...    E-003105-13   \n",
       "7     Directive 2004/82/EC is intended to improve bo...    E-001109-13   \n",
       "8     Directive 2004/82/EC is intended to improve bo...    E-001108-13   \n",
       "9     On 27 February 2013 Mr Kallas on behalf of the...    E-005785-13   \n",
       "10    The Commissioner for Home Affairs has apparent...    P-009654-13   \n",
       "11    On 1 January 2014 Commission Regulation EC No ...    P-007405-13   \n",
       "12    The rights of every EU citizen include the fre...    E-001080-13   \n",
       "13    In divorce cases in Germany maintenance is dec...    E-003342-13   \n",
       "14    The directive on the application of patients r...    E-009518-13   \n",
       "15    It has emerged that the negotiations held betw...    E-003113-14   \n",
       "16    By virtue of circular 2013/151663 concerning i...    E-001705-14   \n",
       "17    The Transatlantic Trade and Investment Partner...    E-004788-14   \n",
       "18    The Pescara Marina one of the largest of its k...    E-008226-14   \n",
       "19    Since 1 January 2014 the citizens of Bulgaria ...    E-000247-14   \n",
       "20    0    The number of social networks on the Inte...    E-005382-15   \n",
       "21    2    How would the High Representative charact...    E-009417-13   \n",
       "22    On 19 December 2011 a Congolese citizen Samba ...    E-004349-13   \n",
       "23    Since the 2009 coup dÃÂÃÂÃÂÃÂ©tat which...    E-010806-13   \n",
       "24    I understand that correspondence has been exch...    E-010948-13   \n",
       "25    On 6 June 2013 a whistleblower exposed an exte...    E-006782-13   \n",
       "26    According to the Amended Work Programme 2013 o...    E-012119-13   \n",
       "27    Recent media reports have clearly exposed the ...    E-005640-13   \n",
       "28    At the beginning of 2012 the operators of the ...    E-004662-13   \n",
       "29    When asked about the possibility that oil pric...    E-005857-13   \n",
       "...                                                 ...            ...   \n",
       "2831  The Ebro Delta with its 22 000 hectares of ric...    E-002675-15   \n",
       "2832  Hungary has decided to deploy armed forces up ...    E-013058-15   \n",
       "2833  Due account must be taken in the following que...    E-008068-15   \n",
       "2834  While larger conflicts including the continuin...    E-003054-15   \n",
       "2835  The Pero Spaccone district on the Formicoso pl...      P-5647/08   \n",
       "2836  A few days ago the Italian press reported an a...      E-3260/07   \n",
       "2837  Maintenance technicians working for Aircraft I...      E-4798/07   \n",
       "2838  The Social Platform has informed me that the L...      E-0252/05   \n",
       "2839  In view of the fact that the Turkish Prime Min...      E-2443/05   \n",
       "2840  The Nitrates Directive 91/676/EEC1 requires Me...      P-4457/08   \n",
       "2841  According to various Arab diplomats the Tunisi...      E-4657/05   \n",
       "2842  1. Does the Commission remember that in March ...      E-1714/01   \n",
       "2843  Economic and social policy-makers in the Europ...      E-2418/01   \n",
       "2844  The Romanian Government has suspended internat...      P-2485/01   \n",
       "2845  Developing countries are in great need of a ma...      E-1790/99   \n",
       "2846  On 22 September 2004 Heineken stated that it w...      P-3527/04   \n",
       "2847  The Italian  ENI through its subsidiary Agip O...      P-1182/05   \n",
       "2848  The Directive of the European Parliament and o...      H-0532/05   \n",
       "2849  How many Erasmus and Erasmus Mundus students s...    E-006550-14   \n",
       "2850  I have noticed that in some EU Member States i...      E-3399/00   \n",
       "2851  Will the Commission state whether there is a E...      E-1818/03   \n",
       "2852  With regard to my question H-0459/02 tabled on...      H-0601/02   \n",
       "2853  In the MÃÂÃÂÃÂÃÂ¼ller-FaurÃÂÃÂÃÂÃ...      P-3666/03   \n",
       "2854  The French authorities are reported to have su...      E-2057/97   \n",
       "2855  Will the Commission state how much of the appr...      E-3404/95   \n",
       "2856  Written Question P-3862/981 criticised the fai...      P-0201/00   \n",
       "2857  The international steel trade faces new challe...      E-3830/98   \n",
       "2858  Shortly after Serbia was granted candidate sta...  E-006504/2012   \n",
       "2859  The increasing shortfall in the numbers of lic...      E-3161/06   \n",
       "2860  Given the move towards a more market-led Europ...      E-5091/07   \n",
       "\n",
       "      Euroskepticism_Score  Nationalism_Score  Populism_Score  \n",
       "0                      0.0                0.0             0.0  \n",
       "1                      1.0                0.0             1.0  \n",
       "2                      0.0                0.0             0.0  \n",
       "3                      0.0                0.0             0.0  \n",
       "4                      0.0                0.0             0.0  \n",
       "5                      0.0                0.0             0.0  \n",
       "6                      1.0                0.0             0.0  \n",
       "7                      0.0                0.0             0.0  \n",
       "8                      0.0                0.0             0.0  \n",
       "9                      1.0                0.0             0.0  \n",
       "10                     0.0                0.0             0.0  \n",
       "11                     1.0                0.0             1.0  \n",
       "12                     0.0                0.0             0.0  \n",
       "13                     1.0                0.0             0.0  \n",
       "14                     0.0                0.0             0.0  \n",
       "15                     0.0                0.0             0.0  \n",
       "16                     0.0                0.0             0.0  \n",
       "17                     0.0                0.0             0.0  \n",
       "18                     1.0                1.0             0.0  \n",
       "19                     0.0                0.0             0.0  \n",
       "20                     0.0                0.0             0.0  \n",
       "21                     0.0                0.0             0.0  \n",
       "22                     1.0                0.0             1.0  \n",
       "23                     1.0                0.0             1.0  \n",
       "24                     0.0                0.0             0.0  \n",
       "25                     1.0                0.0             0.0  \n",
       "26                     0.0                0.0             0.0  \n",
       "27                     0.0                0.0             0.0  \n",
       "28                     0.0                0.0             0.0  \n",
       "29                     1.0                0.0             1.0  \n",
       "...                    ...                ...             ...  \n",
       "2831                   0.0                0.0             0.0  \n",
       "2832                   0.0                0.0             0.0  \n",
       "2833                   0.0                0.0             0.0  \n",
       "2834                   0.0                0.0             0.0  \n",
       "2835                   0.0                0.0             0.0  \n",
       "2836                   1.0                1.0             0.0  \n",
       "2837                   1.0                0.0             0.0  \n",
       "2838                   0.0                0.0             0.0  \n",
       "2839                   0.0                1.0             0.0  \n",
       "2840                   0.0                0.0             0.0  \n",
       "2841                   0.0                0.0             0.0  \n",
       "2842                   1.0                0.0             0.0  \n",
       "2843                   0.0                0.0             0.0  \n",
       "2844                   0.0                0.0             0.0  \n",
       "2845                   0.0                0.0             1.0  \n",
       "2846                   0.0                0.0             0.0  \n",
       "2847                   0.0                0.0             0.0  \n",
       "2848                   1.0                0.0             0.0  \n",
       "2849                   0.0                0.0             0.0  \n",
       "2850                   0.0                0.0             0.0  \n",
       "2851                   0.0                0.0             0.0  \n",
       "2852                   1.0                0.0             0.0  \n",
       "2853                   0.0                0.0             1.0  \n",
       "2854                   0.0                0.0             0.0  \n",
       "2855                   0.0                0.0             0.0  \n",
       "2856                   0.0                0.0             0.0  \n",
       "2857                   0.0                0.0             0.0  \n",
       "2858                   0.0                0.0             0.0  \n",
       "2859                   0.0                0.0             0.0  \n",
       "2860                   0.0                0.0             1.0  \n",
       "\n",
       "[2861 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.to_csv(\"merged_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(scores['Euroskepticism_Score'].unique())\n",
    "print(scores['Nationalism_Score'].unique())\n",
    "print(scores['Populism_Score'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f44a2b088f42f095850a00f2b9bdbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2758af22eb0944c6bea6736fba5ea9bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59aee792cb3f40b7b9ecad1843d0837c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "from platform import python_version\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.autograd import Variable\n",
    "\n",
    "model_class = transformers.BertModel\n",
    "tokenizer_class = transformers.BertTokenizer\n",
    "pretrained_weights='bert-base-uncased'\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "bert_model = model_class.from_pretrained(pretrained_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq = 100\n",
    "def tokenize_text(df, col, max_seq):\n",
    "    return [\n",
    "        tokenizer.encode(text, add_special_tokens=True)[:max_seq] for text in df[col].values\n",
    "    ]\n",
    "def pad_text(tokenized_text, max_seq):\n",
    "    return np.array([el + [0] * (max_seq - len(el)) for el in tokenized_text])\n",
    "def tokenize_and_pad_text(df, max_seq):\n",
    "    tokenized_text = tokenize_text(df, 'Question_Text',max_seq)\n",
    "    padded_text = pad_text(tokenized_text, max_seq)\n",
    "    return torch.tensor(padded_text)\n",
    "def targets_to_tensor(df, target_columns):\n",
    "    return torch.tensor(df[target_columns].values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = scores[0:2000]\n",
    "df_val = scores[2000:2500]\n",
    "df_test = scores[2500:2861]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (601 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (511 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (564 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (521 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (555 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (685 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (512 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'target_columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-5d88f7d28c46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mx_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'target_columns' is not defined"
     ]
    }
   ],
   "source": [
    "train_indices = tokenize_and_pad_text(df_train, max_seq)\n",
    "val_indices = tokenize_and_pad_text(df_val, max_seq)\n",
    "test_indices = tokenize_and_pad_text(df_test, max_seq)\n",
    "with torch.no_grad():\n",
    "    x_train = bert_model(train_indices)[0]  \n",
    "    x_val = bert_model(val_indices)[0]\n",
    "    x_test = bert_model(test_indices)[0]\n",
    "\n",
    "target_columns = ['Euroskepticism_Score']\n",
    "y_train = targets_to_tensor(df_train, target_columns)\n",
    "y_val = targets_to_tensor(df_val, target_columns)\n",
    "y_test = targets_to_tensor(df_test, target_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_columns = ['Euroskepticism_Score']\n",
    "y_train = targets_to_tensor(df_train, target_columns)\n",
    "y_val = targets_to_tensor(df_val, target_columns)\n",
    "y_test = targets_to_tensor(df_test, target_columns)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D CNN for text classification with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected embedding_2_input to have 2 dimensions, but got array with shape torch.Size([2000, 100, 768])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-71f00d90a5c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m           validation_data=(x_test, y_test))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    133\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected embedding_2_input to have 2 dimensions, but got array with shape torch.Size([2000, 100, 768])"
     ]
    }
   ],
   "source": [
    "max_features = 5000 #limit vocab \n",
    "maxlen = 400 #word sequence length\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "filters = 250\n",
    "kernel_size = 3 #filter dim\n",
    "hidden_dims = 250\n",
    "epochs = 6\n",
    "\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "# we start off with an efficient embedding layer which maps\n",
    "# our vocab indices into embedding_dims dimensions\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# word group filters of size filter_length:\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))  #fraction of neurons to drop\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X, scores['Populism_Score'], test_size = .3)\n",
    "y_test_np = y_test.to_numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_measure(y_actual, y_pred):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_pred)): \n",
    "        if y_actual[i]==y_pred[i]==1:\n",
    "           TP += 1\n",
    "        if y_pred[i]==1 and y_actual[i]!=y_pred[i]:\n",
    "           FP += 1\n",
    "        if y_actual[i]==y_pred[i]==0:\n",
    "           TN += 1\n",
    "        if y_pred[i]==0 and y_actual[i]!=y_pred[i]:\n",
    "           FN += 1\n",
    "\n",
    "    A = np.array([[TN, FP], [FN, TP]])\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test = y_actual\n",
    "pop_cm = perf_measure(y_test_np, np.argmax(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"confusion matrix: \\n\",  pop_cm, \"\\n\")\n",
    "print(\"matthews_corrcoef:  {:.4f}\".format(matthews_corrcoef(y_test_np, np.argmax(y_pred, axis=1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM with Keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters:\n",
    "max_features = 5000\n",
    "maxlen = 400\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "hidden_dims = 250\n",
    "# epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy', #different loss function may be needed\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=2,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
